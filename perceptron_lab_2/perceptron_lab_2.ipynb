{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pdb import set_trace as debugger\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas\n",
    "    \n",
    "def upload_cifar(filename):\n",
    "    import cPickle\n",
    "    fo = open(filename, 'rb')\n",
    "    data = cPickle.load(fo)\n",
    "    fo.close()\n",
    "\n",
    "    features = data['data']\n",
    "    labels = data['labels']\n",
    "    labels = np.atleast_2d( labels ).T \n",
    "    \n",
    "    # squash classes 0-4 into class 0, and squash classes 5-9 into class 1\n",
    "    labels[ labels < 5 ] = 0 \n",
    "    labels[ labels >= 5 ] = 1 \n",
    "    return features, labels\n",
    "\n",
    "def upload_iris(filename):\n",
    "    data = pandas.read_csv(filename)\n",
    "    m = data.as_matrix()\n",
    "    labels = m[:,0]\n",
    "    labels[ labels==2 ] = 1  # squash class 2 into class 1\n",
    "    labels = np.atleast_2d( labels ).T \n",
    "    features = m[:,1:5]\n",
    "    return features, labels\n",
    "\n",
    "### Perceptron class; it mainly trains the weights for us to use later\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, features, labels, c = 1, theta = 0):\n",
    "        self.c = c\n",
    "        self.theta = theta\n",
    "        # Add a bias input into every instance\n",
    "        self.features = np.insert(features, features.shape[1], 1, axis=1)\n",
    "        self.labels = labels  \n",
    "        # Create a (1,n+1) matrix of weights, +1 for bias input\n",
    "        self._w = np.matrix(np.random.rand(features.shape[1] + 1))\n",
    "        # L2 norm change list\n",
    "        self.l2_change = [sqrt(self._w.dot(self._w.T).item())]\n",
    "        \n",
    "    def run(self):\n",
    "        for _ in tqdm(xrange(100)):\n",
    "            for instance, label in zip(self.features, self.labels):\n",
    "                # Get our prediction \n",
    "                z_pred = int(self._w.dot(instance).item() > self.theta)\n",
    "                # Compare to label and adjust weights if necessary\n",
    "                lbl = label.item()\n",
    "                if lbl != z_pred: \n",
    "                    self.adjust_weights(lbl - z_pred, instance)\n",
    "            # Compute and save the L2 norm for an epoch\n",
    "            self.l2_change.append(sqrt(self._w.dot(self._w.T).item()))\n",
    "            \n",
    "\n",
    "    def adjust_weights(self, learning_direction, instance):\n",
    "        weight_changes = np.multiply(instance, (self.c * learning_direction))\n",
    "        self._w = np.add(self._w, weight_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Plotting functions ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracy(dataset_name, models, test_features, test_labels):\n",
    "    pass\n",
    "\n",
    "def plot_l2_norm(dataset_name, models):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 278.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 276.75it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 271.35it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Run perceptron on IRIS dataset #####\n",
    "from collections import namedtuple\n",
    "\n",
    "# Namedtuple  to hold perceptron data\n",
    "ntuple = namedtuple(\"Perceptron\", ['learning_rate', 'weights', 'l2_change'])\n",
    "\n",
    "iris_models = list()\n",
    "features, labels = upload_iris(\"Fisher.csv\")\n",
    "for l_rate in [1, 0.1, 0.01]:\n",
    "    # Run perceptron\n",
    "    prcp = Perceptron(features, labels, c=l_rate)\n",
    "    prcp.run()\n",
    "    # Save the model data to plot later\n",
    "    iris_models.append(ntuple(l_rate, prcp._w, prcp.l2_change))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Plot IRIS model data ###\n",
    "\n",
    "test_features, test_labels = features, labels\n",
    "plot_accuracy('IRIS', iris_models, test_features, test_labels)\n",
    "plot_l2_norm('IRIS', iris_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  2.02it/s]\n",
      "100%|██████████| 100/100 [00:47<00:00,  2.09it/s]\n",
      "100%|██████████| 100/100 [00:52<00:00,  1.78it/s]\n",
      "100%|██████████| 100/100 [00:50<00:00,  2.15it/s]\n",
      "100%|██████████| 100/100 [00:52<00:00,  2.13it/s]\n",
      "100%|██████████| 100/100 [00:53<00:00,  2.06it/s]\n",
      "100%|██████████| 100/100 [00:52<00:00,  2.03it/s]\n",
      "100%|██████████| 100/100 [00:50<00:00,  2.08it/s]\n",
      "100%|██████████| 100/100 [00:57<00:00,  1.91it/s]\n",
      "100%|██████████| 100/100 [01:00<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Run perceptron on CIFAR-10 dataset #####\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "cifar_models = defaultdict(list)\n",
    "BASE_DIR = 'cifar-10-batches-py'\n",
    "\n",
    "for f_name in filter(lambda x: 'data' in x, os.listdir(BASE_DIR)):\n",
    "    # Get relative path to file\n",
    "    f_path = os.path.join(BASE_DIR, f_name)\n",
    "    features, labels = upload_cifar(f_path)\n",
    "    for l_rate in [0.001, 0.00001]:\n",
    "        prcp = Perceptron(features, labels, c=l_rate)\n",
    "        prcp.run()\n",
    "        # Save the model data to plot later\n",
    "        cifar_models[f_path].append(ntuple(l_rate, prcp._w, prcp.l2_change))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### Plot CIFAR-10 model data ###\n",
    "\n",
    "for f_path, models in cifar_models.iteritems():\n",
    "    test_features, test_labels = None, None # There's a test batch there...\n",
    "    plot_accuracy(f_path, models, test_features, test_labels)\n",
    "    plot_l2_norm(f_path, models)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
